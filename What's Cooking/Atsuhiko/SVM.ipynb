{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "d96abc737208de7a4cc86c8698346fe78517afa2"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "0bb07acbf975abfcf52a27ac2e8054f96fa55001"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>romaine lettuce, black olives, grape tomatoes,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>plain flour, ground pepper, salt, tomatoes, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>eggs, pepper, salt, mayonaise, cooking oil, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>water, vegetable oil, wheat, salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>black pepper, shallots, cornflour, cayenne pep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients\n",
       "0  10259        greek  romaine lettuce, black olives, grape tomatoes,...\n",
       "1  25693  southern_us  plain flour, ground pepper, salt, tomatoes, gr...\n",
       "2  20130     filipino  eggs, pepper, salt, mayonaise, cooking oil, gr...\n",
       "3  22213       indian                  water, vegetable oil, wheat, salt\n",
       "4  13162       indian  black pepper, shallots, cornflour, cayenne pep..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_json('./data/train.json')\n",
    "test = pd.read_json('./data/test.json')\n",
    "train.ingredients = train.ingredients.apply(lambda l: \", \".join(l))\n",
    "test.ingredients = test.ingredients.apply(lambda l: \", \".join(l))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "4d003f7e86c3b32b8d9a9d96f58b9a1f8ffe39cb"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# words - (\\w+?)(?:,\\s|\\s|$)    ingredients - (.+?)(?:,\\s|$)\n",
    "vectorizerIngr = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None,\\\n",
    "                             max_features = 50000, binary = False, token_pattern=r'(.+?)(?:,\\s|$)') \n",
    "vectorizerIngr.fit(train['ingredients'])\n",
    "bagOfWords = vectorizerIngr.transform(train['ingredients'])\n",
    "bagOfWordsTest = vectorizerIngr.transform(test['ingredients'])\n",
    "\n",
    "vectorizerWords = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None,\\\n",
    "                             max_features = 50000, binary = False, token_pattern=r'(\\w+?)(?:,\\s|\\s|$)') \n",
    "vectorizerWords.fit(train['ingredients'])\n",
    "bagOfWordsWords = vectorizerWords.transform(train['ingredients'])\n",
    "bagOfWordsTestWords = vectorizerWords.transform(test['ingredients'])\n",
    "\n",
    "vectorizerTfDf =  TfidfVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None,\\\n",
    "                             max_features = 50000, binary = False, token_pattern=r'(\\w+?)(?:,\\s|\\s|$)')\n",
    "\n",
    "vectorizerTfDf.fit(train['ingredients'])\n",
    "bagOfWordsTfDf = vectorizerTfDf.transform(train['ingredients'])\n",
    "bagOfWordsTestTfDf = vectorizerTfDf.transform(test['ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "6ed44c1bdbd9617a52a0eb4f99c1d272cf28ac2f"
   },
   "outputs": [],
   "source": [
    "import warnings, sklearn\n",
    "import scipy.sparse as sparse\n",
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "318ef5ed67d2db0be258ec7daee612d3d41d647e"
   },
   "outputs": [],
   "source": [
    "bagOfWords = bagOfWords.astype('float')\n",
    "bagOfWordsWords = bagOfWordsWords.astype('float')\n",
    "from sklearn.cluster import KMeans\n",
    "#clusters = KMeans(n_clusters=2, random_state=0).fit_predict(data0)\n",
    "#clusterDummies = pd.get_dummies(clusters, prefix='cluster')\n",
    "\n",
    "kolvoWords = np.sum(bagOfWordsWords, axis=1)\n",
    "kolvoIngr = np.sum(bagOfWords, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "4dd4c7b5eec6ddc3fd9f15f4103bbcac576e9d3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.3, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdaKolvoIngr =  0.0606\n",
    "lambdaKolvoWords = 0.05\n",
    "lambdaTfDf = 1\n",
    "lambdaBagOfW = 0.2121\n",
    "lambdaWords = 0.116\n",
    "#data1 = sparse.hstack((data0, clusterDummies*lambdaClusters, kolvo*lambdaKolvo))\n",
    "data1 = sparse.hstack((lambdaTfDf * bagOfWordsTfDf, \\\n",
    "                       bagOfWords * lambdaBagOfW, \\\n",
    "                       bagOfWordsWords * lambdaWords, \\\n",
    "                       kolvoWords*lambdaKolvoWords, \\\n",
    "                       kolvoIngr*lambdaKolvoIngr))\n",
    "\n",
    "SVM = svm.LinearSVC(C=0.3)\n",
    "SVM.fit(data1, train['cuisine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "0d43fe936b6ae4071181a4718f665c25785a3dba"
   },
   "outputs": [],
   "source": [
    "bagOfWordsTest = bagOfWordsTest.astype('float')\n",
    "bagOfWordsTestWords = bagOfWordsTestWords.astype('float')\n",
    "\n",
    "kolvoWordsTest = np.sum(bagOfWordsTestWords, axis=1)\n",
    "kolvoIngrTest = np.sum(bagOfWordsTest, axis=1)\n",
    "\n",
    "dataTest = sparse.hstack((lambdaTfDf * bagOfWordsTestTfDf, \\\n",
    "                       bagOfWordsTest * lambdaBagOfW, \\\n",
    "                       bagOfWordsTestWords * lambdaWords, \\\n",
    "                       kolvoWordsTest*lambdaKolvoWords, \\\n",
    "                       kolvoIngrTest*lambdaKolvoIngr))\n",
    "#res = SVM.predict(dataTest)\"\"\"\n",
    "class FuncCreator:\n",
    "    def __init__(self):\n",
    "        self.dict_cuisine = dict()\n",
    "        self.ind = 0\n",
    "    def __call__(self, it):\n",
    "        x = it.lower()\n",
    "        if not (x in self.dict_cuisine.keys()):\n",
    "            self.dict_cuisine[x] = self.ind\n",
    "            self.ind = self.ind + 1\n",
    "        return it\n",
    "    \n",
    "    def getNameFromId(self, id):\n",
    "        for key, val in self.dict_cuisine.items():\n",
    "            if (val == id):\n",
    "                return key\n",
    "        return \"UNKNOW\"\n",
    "    \n",
    "class MySVM:\n",
    "    def __init__(self, C=0.3):\n",
    "        self.SVMS = dict()\n",
    "        self.rep = FuncCreator()\n",
    "        self.keys=[]\n",
    "        self.C=C\n",
    "        \n",
    "    def learn(self, data1, y, res, ar=[]):\n",
    "        self.rep = FuncCreator()\n",
    "        y.apply(self.rep)\n",
    "        self.keys=np.array(list(self.rep.dict_cuisine.keys()))\n",
    "        i = 0\n",
    "        for key in self.keys:\n",
    "            #print(key)\n",
    "            ndata=y==key\n",
    "            #print(ndata)\n",
    "            if (i >= len(ar)):\n",
    "                SVM = svm.LinearSVC(C=self.C)\n",
    "            else:\n",
    "                SVM = svm.LinearSVC(C=ar[i])\n",
    "            SVM.fit(data1, ndata)\n",
    "            self.SVMS[key] = SVM\n",
    "            i = i + 1\n",
    "            \n",
    "    def predict(self, data, ar=[]):\n",
    "        arr = np.zeros((data.shape[0],len(self.keys)))\n",
    "        i = 0\n",
    "        for key in self.keys:\n",
    "            if (len(ar) == 0 or ((len(ar)) < len(self.rep.dict_cuisine.keys()))):\n",
    "                arr[:,i]=self.SVMS[key].decision_function(data)\n",
    "            else:\n",
    "                arr[:,i]=ar[i] * self.SVMS[key].decision_function(data)\n",
    "            i = i+1\n",
    "        return self.keys[np.argmax(arr, axis=1)]\n",
    "    \n",
    "SVM = MySVM(C=0.29)\n",
    "SVM.learn(data1, train['cuisine'], 0, [0.25, 0.4, 0.25, 0.25, 0.1, 0.3, 0.3, 0.3, 0.2, 0.35, 0.35, 0.5, 0.25, 0.3, 0.3, 0.35, 0.6, 0.4, 0.55, 0.45])\n",
    "res = SVM.predict(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "814180d16f117faf8274046e6cf70f1acadfa936"
   },
   "outputs": [],
   "source": [
    "f =open(\"svm_output.csv\", \"w\")\n",
    "f.write(\"id,cuisine\\n\")\n",
    "i = 0\n",
    "for item in test[\"id\"]:\n",
    "    f.write(str(item))\n",
    "    f.write(\",\")\n",
    "    f.write(res[i])\n",
    "    f.write(\"\\n\")\n",
    "    i= i +1\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3c84e24fb7185292fb01c709c986acb4fc56f40"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
