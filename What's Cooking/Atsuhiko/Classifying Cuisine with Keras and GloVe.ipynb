{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe （Global Vectors for Word Representation）とは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://nonbiri-tereka.hatenablog.com/entry/2015/10/25/223430\n",
    "\n",
    "GloVeとは、Global Vectors for Word Representationの略です。その名の通り、ワードを表現する大域的な特徴ベクトルを計算します。単語をD次元ベクトルに変換することができ、言葉と言葉の距離の計算を可能とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "4c1a412b-4535-46d5-8fe3-e8600801817a",
    "_uuid": "4e6801037e5274668f0b8667591d41c1abbe8be1"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "#from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "00d2aeb7-f5f6-407f-9a93-3bd76a6a07ff",
    "_uuid": "e88af6df71dc71c31208047b965ac30cdbf39729"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredientsFlat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>romaine lettuce black olives grape tomatoes ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>plain flour ground pepper salt tomatoes ground...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>eggs pepper salt mayonaise cooking oil green c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>water vegetable oil wheat salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>black pepper shallots cornflour cayenne pepper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients  \\\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3  22213       indian                [water, vegetable oil, wheat, salt]   \n",
       "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "                                     ingredientsFlat  \n",
       "0  romaine lettuce black olives grape tomatoes ga...  \n",
       "1  plain flour ground pepper salt tomatoes ground...  \n",
       "2  eggs pepper salt mayonaise cooking oil green c...  \n",
       "3                     water vegetable oil wheat salt  \n",
       "4  black pepper shallots cornflour cayenne pepper...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "recipeRaw = pd.read_json(\"./data/train.json\")\n",
    "recipeRaw[\"ingredientsFlat\"] = recipeRaw[\"ingredients\"].apply(lambda x: ' '.join(x))\n",
    "recipeRaw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "0e1f7eab-ffa0-446a-9c34-daae03c16379",
    "_uuid": "1db441bec8a629339122deb853f4757a7f5c8df7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\301518\\AppData\\Local\\Continuum\\anaconda3\\envs\\Python3.6-gpu\\lib\\site-packages\\pandas\\core\\frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredientsFlat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14989</td>\n",
       "      <td>[garlic cloves, chicken, dry white wine, fresh...</td>\n",
       "      <td>garlic cloves chicken dry white wine fresh bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13270</td>\n",
       "      <td>[egg whites, all-purpose flour, eggs, almond e...</td>\n",
       "      <td>egg whites all-purpose flour eggs almond extra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25529</td>\n",
       "      <td>[tomato sauce, refrigerated pizza dough, olive...</td>\n",
       "      <td>tomato sauce refrigerated pizza dough olive oi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12140</td>\n",
       "      <td>[kosher salt, whole milk yoghurt, heavy cream,...</td>\n",
       "      <td>kosher salt whole milk yoghurt heavy cream cay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23127</td>\n",
       "      <td>[avocado, pork, lime, flour, shredded sharp ch...</td>\n",
       "      <td>avocado pork lime flour shredded sharp cheddar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cuisine     id                                        ingredients  \\\n",
       "226     NaN  14989  [garlic cloves, chicken, dry white wine, fresh...   \n",
       "227     NaN  13270  [egg whites, all-purpose flour, eggs, almond e...   \n",
       "228     NaN  25529  [tomato sauce, refrigerated pizza dough, olive...   \n",
       "229     NaN  12140  [kosher salt, whole milk yoghurt, heavy cream,...   \n",
       "230     NaN  23127  [avocado, pork, lime, flour, shredded sharp ch...   \n",
       "\n",
       "                                       ingredientsFlat  \n",
       "226  garlic cloves chicken dry white wine fresh bas...  \n",
       "227  egg whites all-purpose flour eggs almond extra...  \n",
       "228  tomato sauce refrigerated pizza dough olive oi...  \n",
       "229  kosher salt whole milk yoghurt heavy cream cay...  \n",
       "230  avocado pork lime flour shredded sharp cheddar...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipeRawTest = pd.read_json(\"./data/test.json\")\n",
    "recipeRawTest[\"ingredientsFlat\"] = recipeRawTest[\"ingredients\"].apply(lambda x: ' '.join(x))\n",
    "testdocs = recipeRawTest[\"ingredientsFlat\"].values\n",
    "recipeRawCombined = recipeRaw.append(recipeRawTest)\n",
    "recipeRawCombined[40000:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "a5b844ba-7eb5-4a22-a396-5e23eb23cd85",
    "_uuid": "5ad902e961a68cd09c05269696439abf9d0f8654"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brazilian',\n",
       " 'british',\n",
       " 'cajun_creole',\n",
       " 'chinese',\n",
       " 'filipino',\n",
       " 'french',\n",
       " 'greek',\n",
       " 'indian',\n",
       " 'irish',\n",
       " 'italian',\n",
       " 'jamaican',\n",
       " 'japanese',\n",
       " 'korean',\n",
       " 'mexican',\n",
       " 'moroccan',\n",
       " 'russian',\n",
       " 'southern_us',\n",
       " 'spanish',\n",
       " 'thai',\n",
       " 'vietnamese']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(recipeRaw[\"cuisine\"].values)\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "29a5542b-848b-4428-9217-2000a859a4dc",
    "_uuid": "499cd7566059f69ee184d2e0bb56c58274d7bf8f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "docs = recipeRaw[\"ingredientsFlat\"].values\n",
    "testdocs = recipeRawTest[\"ingredientsFlat\"].values\n",
    "docsCombined = recipeRawCombined[\"ingredientsFlat\"].values\n",
    "labels_enc = le.transform(recipeRaw[\"cuisine\"].values)\n",
    "labels = to_categorical(labels_enc)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "7bcf422f-0e75-4d49-b3b1-12553fcaf4ff",
    "_uuid": "46b7fc9aef5a519f96a295e980ba15deee781e97",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3185\n",
      "39774\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docsCombined)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "encoded_test_docs = t.texts_to_sequences(testdocs)\n",
    "print(vocab_size)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 40\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "padded_test_docs = pad_sequences(encoded_test_docs, maxlen=max_length, padding='post')\n",
    "print(len(padded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "9182c6ea-cd7d-46a1-bd29-a532e0935474",
    "_uuid": "31ef8ec3a8d8a6229dc767a90061dfc50294b456"
   },
   "outputs": [],
   "source": [
    "# didn't work\n",
    "\n",
    "# load the whole embedding into memory\n",
    "#embeddings_index = dict()\n",
    "#f = open('./data/glove.6B.50d.txt')\n",
    "#for line in f:\n",
    "#    values = line.split()\n",
    "#    word = values[0]\n",
    "#    coefs = np.asarray(values[1:], dtype='float32')\n",
    "#    embeddings_index[word] = coefs\n",
    "#f.close()\n",
    "#print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe 辞書の読み込み --> Jigsaw Toxic Comments の notebook より\n",
    "# https://pycarnival.com/dict/\n",
    "\n",
    "path = './data/'\n",
    "EMBEDDING_FILE=f'{path}glove.6B.100d.txt'\n",
    "# Glove の Word Vector (https://www.kaggle.com/watts2/glove6b50dtxt)\n",
    "\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "# 単一の星*は配列/コレクションを位置引数に展開\n",
    "# 「* x」引数を取る関数を定義することで、宣言することなく多数のオプションパラメータを指定することができる。\n",
    "# https://codeday.me/jp/qa/20181122/11424.html\n",
    "\n",
    "import json\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE, encoding=\"utf-8_sig\"))\n",
    "# split() カンマ区切り文字列を分割、空白を削除しリスト化\n",
    "\n",
    "# UnicodeDecodeError: 'cp932' codec can't decode byte 0x93 in position 3136: illegal multibyte sequence を回避するため、\n",
    "# open(EMBEDDING_FILE) --> open(EMBEDDING_FILE, encoding=\"utf-8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "97ec3b51-53be-4078-a72a-a4222d2ffac0",
    "_uuid": "72b42e2a27337810e4604db0f67d626a62008854"
   },
   "outputs": [],
   "source": [
    "vocab = pd.DataFrame.from_dict(t.word_index,orient=\"index\")\n",
    "vocab.drop([0],axis=1).reset_index().rename(columns={\"index\":\"word\"}).to_csv(\"vocab.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "fa875535-7cef-40da-9add-dfe1d51395b0",
    "_uuid": "befd8941982ee2119daa0b9cc6b10a1e14656239"
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "593bfd0a-b703-4e87-96dd-a7eb98e6940e",
    "_uuid": "f71c5f0b731d3418d3cb83be758233b5030da29d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3185, 100)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "890c0395-03d7-4608-b540-8ec2401b96a2",
    "_uuid": "225c77061e58aa23140df026385bf7cbc02e58e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40, 100)           318500    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 40, 100)           30100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               500250    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                5020      \n",
      "=================================================================\n",
      "Total params: 853,870\n",
      "Trainable params: 535,370\n",
      "Non-trainable params: 318,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "acc: 97.30%\n",
      "acc: 97.14%\n",
      "acc: 97.02%\n",
      "acc: 97.03%\n",
      "acc: 97.10%\n",
      "97.12% (+/- 0.10%)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "cvscores = []\n",
    "for train, test in kfold.split(padded_docs, labels):\n",
    "    # define the model\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=40, trainable=False))\n",
    "    model.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(le.classes_.size, activation='sigmoid'))\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    # summarize the model\n",
    "    if cvscores == []:\n",
    "        print(model.summary())\n",
    "    # fit the model\n",
    "    model.fit(padded_docs[train], labels[train], epochs=5, verbose=0)\n",
    "    scores = model.evaluate(padded_docs[test], labels[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_cell_guid": "cade4e3e-0feb-4cd1-9dfb-3c7f090b7b44",
    "_uuid": "caaa007d8244b9f7fcd765aa413d248a603fac67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9944, 20)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(padded_test_docs)\n",
    "print(predictions.shape)\n",
    "recipeRawTest[\"cuisine\"] = [le.classes_[np.argmax(prediction)] for prediction in predictions]\n",
    "recipeRawTest.head()\n",
    "recipeRawTest.drop([\"ingredients\",\"ingredientsFlat\"],axis=1).to_csv(\"GloVe_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
